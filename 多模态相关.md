####  1
多模态指令调整（MIT） 如3DMIT
多模态上下文学习（M-ICL）  如Flamingo
多模态思想链（M-CoT）
LLM辅助视觉推理（LAVR） 如LLaVA

#### 模型对齐方法

多模态转换器（Multimodal Transformers）：这种方法通过将不同模态的数据转换成统一的表示形式，使得模型能够以统一的方式处理多模态输入。

多模态感知器（Multimodal Perceptors）：提高模型感知不同类型数据的能力，例如，通过改进模型结构来增强对图像、文本等不同模态数据的感知和理解。

多模态对齐框架（Multimodal Alignment Frameworks）：如LanguageBind框架，它在多种不同模态下进行对齐，如视频、音频、文本等，以实现更准确的多模态信息处理。

强化学习人类反馈（Reinforcement Learning from Human Feedback, RLHF）：例如LLaVA-RLHF模型，使用RLHF的方式来实现大型多模态模型的有效对齐，提高模型的准确性和可靠性。

事实增强的RLHF：在LLaVA-RLHF的基础上，通过引入额外的事实信息来进一步增强模型对齐，解决多模态未对齐的问题。

多模态指令调整（Visual Instruction Tuning）：如LLaVA模型，通过使用纯语言GPT生成多模态语言图像指令遵循数据，并进行指令调整，推出大型语言和视觉助手。

多模态上下文学习（Multimodal In-context Learning, M-ICL）：通过在图文交错的数据上训练来提升模型关注上下文的能力，适用于少样本学习场景。

多模态思维链（Multimodal Chain of Thought, M-CoT）：通过将复杂问题分解为简单子问题，然后分别解决并汇总，实现复杂的多模态推理。

LLM辅助的视觉推理（LLM-Aided Visual Reasoning, LAVR）：探索如何利用大型语言模型的内嵌知识和能力，结合其他工具设计视觉推理系统。
